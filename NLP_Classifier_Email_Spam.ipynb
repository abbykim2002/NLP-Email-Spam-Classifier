{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Classifier_Email_Spam",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pse61rAUwwfT"
      },
      "source": [
        "# import libraries\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import sklearn"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCM2rlRyw9uc",
        "outputId": "cf52d898-a65c-452c-8201-b958ea94a336"
      },
      "source": [
        "# load dataframe https://www.kaggle.com/datatattle/email-classification-nlp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df_train = pd.read_csv('/content/SMS_train.csv', header=None, encoding = 'ISO-8859-1')[1:]\n",
        "df_test = pd.read_csv('/content/SMS_test.csv', header=None, encoding = 'ISO-8859-1')[1:]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojdJJCcSyzkF"
      },
      "source": [
        "# check to see if data loaded correctly, gain some insight into data\n",
        "# print(df_train.info())\n",
        "# print(df_train.head())\n",
        "# print(df_test.info())\n",
        "# print(df_test.head())"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCmBu0Df0eab"
      },
      "source": [
        "# check class distribution\n",
        "classes_train = df_train[2]\n",
        "classes_test = df_test[2]\n",
        "# print(\"train:\\n\",classes_train.value_counts())\n",
        "# print(\"test:\\n\",classes_test.value_counts())"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5jJx4ER1oyX"
      },
      "source": [
        "# begin preprocessing data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# convert class labels to binary values, 0 = ham and 1 = spam\n",
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(classes_train)\n",
        "Y_test = encoder.fit_transform(classes_test)\n",
        "\n",
        "# print(Y_train[:10])\n",
        "# print(Y_test[:10])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEst2wEc2rHs"
      },
      "source": [
        "# store the email message data\n",
        "messages_train = df_train[1]\n",
        "messages_test = df_test[1]\n",
        "# print(messages_train[:10])\n",
        "# print(messages_test[:10])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmPIOP2d4izv"
      },
      "source": [
        "# preprocess message data\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def process_messages(processed_arg):\n",
        "  # change all words to lower case\n",
        "  processed = processed_arg.str.lower()\n",
        "\n",
        "  # use regular expressions to clean data\n",
        "\n",
        "  # Replace email addresses with 'email'\n",
        "  processed = processed.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
        "\n",
        "  # Replace URLs with 'webaddress'\n",
        "  processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
        "\n",
        "  # Replace money symbols with 'moneysymb'\n",
        "  processed = processed.str.replace(r'Â£|\\$', 'moneysymb')\n",
        "      \n",
        "  # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "  processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumbr')\n",
        "      \n",
        "  # Replace numbers with 'numbr'\n",
        "  processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
        "\n",
        "  # Remove punctuation\n",
        "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "  # Replace whitespace between terms with a single space\n",
        "  processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "  # Remove leading and trailing whitespace\n",
        "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
        "\n",
        "  # Remove stop words from text messages\n",
        "  processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
        "\n",
        "  # Remove word stems using a Porter stemmer\n",
        "  return processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))\n",
        "\n",
        "processed_train = process_messages(messages_train)\n",
        "# print(processed_train)\n",
        "processed_test = process_messages(messages_test)\n",
        "# print(processed_test)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viW0RlBB8564"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# create bag of words\n",
        "all_words = []\n",
        "\n",
        "for message in processed_train:\n",
        "    words = word_tokenize(message)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "        \n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqOuInMeH8wU",
        "outputId": "9059504b-50c6-43bb-b5b7-3fa9702c24a0"
      },
      "source": [
        "# print the total number of words and the 15 most common words\n",
        "print('Number of words: {}'.format(len(all_words)))\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 2484\n",
            "Most common words: [('numbr', 478), ('u', 207), ('call', 124), ('go', 81), ('get', 75), ('ur', 66), ('moneysymbnumbr', 57), ('free', 47), ('come', 46), ('ok', 45), ('time', 44), ('gt', 43), ('day', 42), ('lt', 41), ('like', 40)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKZw75csII34"
      },
      "source": [
        "# use 1000 most common words as features\n",
        "word_features = list(all_words.keys())[:1000]\n",
        "\n",
        "# The find_features function will determine which of the 1000 word features are contained in the review\n",
        "def find_features(message):\n",
        "    words = word_tokenize(message)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[word] = (word in words)\n",
        "    return features"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJhlcKORIe6v"
      },
      "source": [
        "messages_train = list(zip(processed_train, Y_train))\n",
        "messages_test = list(zip(processed_test, Y_test))\n",
        "\n",
        "# define a seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed = seed\n",
        "np.random.shuffle(messages_train)\n",
        "np.random.shuffle(messages_test)\n",
        "\n",
        "# call find_features function for each email\n",
        "training = [(find_features(text), label) for (text, label) in messages_train]\n",
        "testing = [(find_features(text), label) for (text, label) in messages_test]"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJeS4U04KMH4",
        "outputId": "5c206ea3-b3c4-4ed2-966b-f77e38a7357e"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Define models to train\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = list(zip(names, classifiers))\n",
        "\n",
        "for name, model in models:\n",
        "    nltk_model = SklearnClassifier(model)\n",
        "    nltk_model.train(training)\n",
        "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "    print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors Accuracy: 51.2\n",
            "Decision Tree Accuracy: 95.19999999999999\n",
            "Random Forest Accuracy: 88.0\n",
            "Logistic Regression Accuracy: 90.4\n",
            "SGD Classifier Accuracy: 92.80000000000001\n",
            "Naive Bayes Accuracy: 93.60000000000001\n",
            "SVM Linear Accuracy: 91.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laABzGmDO_zt",
        "outputId": "4c20f6a3-a282-4efa-af54-b65e2d5fe23e"
      },
      "source": [
        "# Making a Voting Classifier with the top performing models\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "names = [\"Decision Tree\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    DecisionTreeClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = list(zip(names, classifiers))\n",
        "\n",
        "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
        "nltk_ensemble.train(training)\n",
        "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting Classifier: Accuracy: 91.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXkLISHAP3I3"
      },
      "source": [
        "# make class label prediction for testing set\n",
        "txt_features, labels = zip(*testing)\n",
        "\n",
        "prediction = nltk_ensemble.classify_many(txt_features)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Jg5Ae6RwQM49",
        "outputId": "21cf2366-8363-4270-fe7c-b08c68eb475b"
      },
      "source": [
        "# print a confusion matrix and a classification report\n",
        "print(classification_report(labels, prediction))\n",
        "\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(labels, prediction),\n",
        "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
        "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92        49\n",
            "           1       1.00      0.89      0.94        76\n",
            "\n",
            "    accuracy                           0.94       125\n",
            "   macro avg       0.93      0.95      0.93       125\n",
            "weighted avg       0.94      0.94      0.94       125\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>ham</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
              "      <th>ham</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>8</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            predicted     \n",
              "                  ham spam\n",
              "actual ham         49    0\n",
              "       spam         8   68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryUXO1qoQOqz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}